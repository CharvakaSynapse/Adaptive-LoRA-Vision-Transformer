{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deafe84d-f720-4b69-832c-544236f09952",
   "metadata": {},
   "source": [
    "# DEIT full fine tune CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbdf426b-0544-47f0-8af2-ca6242a093fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program starts...\n",
      "Running Full Fine-Tuning with CutMix (30 Epochs)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DeiTForImageClassification were not initialized from the model checkpoint at facebook/deit-base-distilled-patch16-224 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters before training:\n",
      "Total trainable params: 85877092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 1250/1250 [03:19<00:00,  6.27it/s, Loss=1.0811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.2618, Val Loss: 1.2296, Train Accuracy: 61.52%, Val Accuracy: 85.76%, Time: 220.24s, LR: 0.000020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 1250/1250 [03:20<00:00,  6.23it/s, Loss=1.2700]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 1.6632, Val Loss: 1.1461, Train Accuracy: 73.97%, Val Accuracy: 87.59%, Time: 222.12s, LR: 0.000040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 1250/1250 [03:19<00:00,  6.27it/s, Loss=0.9391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 1.5108, Val Loss: 1.1632, Train Accuracy: 79.11%, Val Accuracy: 87.09%, Time: 220.91s, LR: 0.000059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 1250/1250 [03:20<00:00,  6.25it/s, Loss=0.9713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 1.4212, Val Loss: 1.1688, Train Accuracy: 80.47%, Val Accuracy: 87.07%, Time: 221.60s, LR: 0.000079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 1250/1250 [03:17<00:00,  6.32it/s, Loss=1.5374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Test Loss: 1.2072, Test Accuracy: 85.41%\n",
      "Epoch 5, Train Loss: 1.4219, Val Loss: 1.1986, Train Accuracy: 80.07%, Val Accuracy: 85.96%, Time: 219.02s, LR: 0.000098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 1250/1250 [03:19<00:00,  6.27it/s, Loss=1.2247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved at epoch 6 with Val Accuracy: 87.48%\n",
      "Epoch 6, Train Loss: 1.3679, Val Loss: 1.1696, Train Accuracy: 81.34%, Val Accuracy: 87.48%, Time: 220.64s, LR: 0.000095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 1250/1250 [03:19<00:00,  6.27it/s, Loss=1.1226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 1.3142, Val Loss: 1.2018, Train Accuracy: 83.46%, Val Accuracy: 86.82%, Time: 220.68s, LR: 0.000092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 1250/1250 [03:20<00:00,  6.24it/s, Loss=1.6309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 1.2876, Val Loss: 1.1841, Train Accuracy: 85.13%, Val Accuracy: 87.34%, Time: 221.65s, LR: 0.000089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 1250/1250 [03:19<00:00,  6.27it/s, Loss=0.8716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved at epoch 9 with Val Accuracy: 87.85%\n",
      "Epoch 9, Train Loss: 1.2340, Val Loss: 1.1861, Train Accuracy: 85.53%, Val Accuracy: 87.85%, Time: 220.61s, LR: 0.000085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 1250/1250 [03:19<00:00,  6.26it/s, Loss=0.7920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Test Loss: 1.2176, Test Accuracy: 87.26%\n",
      "Epoch 10, Train Loss: 1.2129, Val Loss: 1.2002, Train Accuracy: 86.32%, Val Accuracy: 87.69%, Time: 221.07s, LR: 0.000081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 1250/1250 [03:18<00:00,  6.29it/s, Loss=0.7885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved at epoch 11 with Val Accuracy: 87.93%\n",
      "Epoch 11, Train Loss: 1.2142, Val Loss: 1.2124, Train Accuracy: 87.13%, Val Accuracy: 87.93%, Time: 220.25s, LR: 0.000076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 1250/1250 [03:18<00:00,  6.30it/s, Loss=1.7682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 1.1940, Val Loss: 1.2064, Train Accuracy: 87.06%, Val Accuracy: 87.87%, Time: 219.72s, LR: 0.000072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 1250/1250 [03:19<00:00,  6.26it/s, Loss=1.6958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved at epoch 13 with Val Accuracy: 87.96%\n",
      "Epoch 13, Train Loss: 1.1698, Val Loss: 1.2021, Train Accuracy: 87.78%, Val Accuracy: 87.96%, Time: 221.02s, LR: 0.000067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 1250/1250 [03:19<00:00,  6.25it/s, Loss=0.7825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved at epoch 14 with Val Accuracy: 88.80%\n",
      "Epoch 14, Train Loss: 1.1485, Val Loss: 1.1889, Train Accuracy: 88.93%, Val Accuracy: 88.80%, Time: 221.38s, LR: 0.000062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 1250/1250 [03:20<00:00,  6.23it/s, Loss=1.6923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Test Loss: 1.1939, Test Accuracy: 88.22%\n",
      "Epoch 15, Train Loss: 1.1536, Val Loss: 1.1954, Train Accuracy: 88.25%, Val Accuracy: 88.64%, Time: 221.75s, LR: 0.000057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 1250/1250 [03:18<00:00,  6.29it/s, Loss=1.6843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved at epoch 16 with Val Accuracy: 88.98%\n",
      "Epoch 16, Train Loss: 1.1330, Val Loss: 1.1758, Train Accuracy: 88.62%, Val Accuracy: 88.98%, Time: 220.14s, LR: 0.000052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 1250/1250 [03:20<00:00,  6.24it/s, Loss=1.3786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train Loss: 1.1418, Val Loss: 1.1899, Train Accuracy: 87.81%, Val Accuracy: 88.86%, Time: 221.90s, LR: 0.000047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 1250/1250 [03:21<00:00,  6.21it/s, Loss=0.7805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Train Loss: 1.1323, Val Loss: 1.1753, Train Accuracy: 88.92%, Val Accuracy: 88.93%, Time: 222.78s, LR: 0.000042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 1250/1250 [03:19<00:00,  6.27it/s, Loss=1.4176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved at epoch 19 with Val Accuracy: 89.18%\n",
      "Epoch 19, Train Loss: 1.1262, Val Loss: 1.1661, Train Accuracy: 88.49%, Val Accuracy: 89.18%, Time: 220.57s, LR: 0.000038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 1250/1250 [03:19<00:00,  6.28it/s, Loss=1.4257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Test Loss: 1.1680, Test Accuracy: 89.25%\n",
      "New best model saved at epoch 20 with Val Accuracy: 89.25%\n",
      "Epoch 20, Train Loss: 1.1247, Val Loss: 1.1708, Train Accuracy: 89.45%, Val Accuracy: 89.25%, Time: 220.28s, LR: 0.000034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 1250/1250 [03:22<00:00,  6.17it/s, Loss=1.5956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved at epoch 21 with Val Accuracy: 89.77%\n",
      "Epoch 21, Train Loss: 1.0988, Val Loss: 1.1550, Train Accuracy: 89.53%, Val Accuracy: 89.77%, Time: 224.07s, LR: 0.000029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 1250/1250 [03:19<00:00,  6.26it/s, Loss=1.4501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved at epoch 22 with Val Accuracy: 89.93%\n",
      "Epoch 22, Train Loss: 1.1095, Val Loss: 1.1490, Train Accuracy: 89.11%, Val Accuracy: 89.93%, Time: 221.32s, LR: 0.000026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 1250/1250 [03:21<00:00,  6.19it/s, Loss=0.7789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved at epoch 23 with Val Accuracy: 89.94%\n",
      "Epoch 23, Train Loss: 1.0946, Val Loss: 1.1506, Train Accuracy: 88.95%, Val Accuracy: 89.94%, Time: 223.52s, LR: 0.000022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 1250/1250 [03:19<00:00,  6.27it/s, Loss=1.8814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Train Loss: 1.0818, Val Loss: 1.1480, Train Accuracy: 90.64%, Val Accuracy: 89.77%, Time: 220.66s, LR: 0.000019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 1250/1250 [03:19<00:00,  6.25it/s, Loss=1.5058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 - Test Loss: 1.1487, Test Accuracy: 89.70%\n",
      "New best model saved at epoch 25 with Val Accuracy: 90.17%\n",
      "Epoch 25, Train Loss: 1.0741, Val Loss: 1.1363, Train Accuracy: 90.44%, Val Accuracy: 90.17%, Time: 221.20s, LR: 0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 1250/1250 [03:19<00:00,  6.25it/s, Loss=0.7789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved at epoch 26 with Val Accuracy: 90.29%\n",
      "Epoch 26, Train Loss: 1.0819, Val Loss: 1.1323, Train Accuracy: 90.32%, Val Accuracy: 90.29%, Time: 221.21s, LR: 0.000014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 1250/1250 [03:20<00:00,  6.24it/s, Loss=0.7787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Train Loss: 1.0856, Val Loss: 1.1367, Train Accuracy: 89.30%, Val Accuracy: 90.19%, Time: 221.67s, LR: 0.000012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 1250/1250 [03:20<00:00,  6.22it/s, Loss=0.7786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Train Loss: 1.0843, Val Loss: 1.1350, Train Accuracy: 89.22%, Val Accuracy: 90.19%, Time: 222.11s, LR: 0.000011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 1250/1250 [03:19<00:00,  6.27it/s, Loss=1.1290]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved at epoch 29 with Val Accuracy: 90.33%\n",
      "Epoch 29, Train Loss: 1.0707, Val Loss: 1.1307, Train Accuracy: 90.90%, Val Accuracy: 90.33%, Time: 220.73s, LR: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 1250/1250 [03:21<00:00,  6.20it/s, Loss=0.7785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 - Test Loss: 1.1354, Test Accuracy: 90.19%\n",
      "Epoch 30, Train Loss: 1.0785, Val Loss: 1.1352, Train Accuracy: 90.83%, Val Accuracy: 90.30%, Time: 223.13s, LR: 0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DeiTForImageClassification were not initialized from the model checkpoint at facebook/deit-base-distilled-patch16-224 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model (Epoch 29) - Test Loss: 1.1345, Test Accuracy: 90.18%\n",
      "ECE: 0.0560, Scaled ECE: 0.0266, Scaled Test Accuracy: 90.18%\n",
      "Class-wise Accuracy: Mean 0.90, Std 0.07\n",
      "Total training time: 6820.82 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from transformers import DeiTForImageClassification\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "from tqdm import tqdm\n",
    "\n",
    "start = time.time()\n",
    "print('Program starts...')\n",
    "print(\"Running Full Fine-Tuning with CutMix (30 Epochs)\")\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(78)\n",
    "torch.manual_seed(78)\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Split training set into train and validation (80/20)\n",
    "dataset_size = len(train_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(0.2 * dataset_size))\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "assert len(set(train_indices) & set(val_indices)) == 0, \"Train-validation overlap detected\"\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_dataset = Subset(train_dataset, val_indices)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=train_sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load DeiT and modify classifier\n",
    "model = DeiTForImageClassification.from_pretrained('facebook/deit-base-distilled-patch16-224')\n",
    "model.classifier = torch.nn.Linear(model.classifier.in_features, 100)\n",
    "\n",
    "# All parameters are trainable for full fine-tuning\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Verify trainable parameters\n",
    "print(\"Trainable parameters before training:\")\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable params: {trainable_params}\")\n",
    "\n",
    "# Validation function\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    all_logits = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_logits.append(outputs.cpu())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    avg_val_loss = val_loss / len(loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    return avg_val_loss, val_accuracy, np.concatenate(all_probs), np.concatenate(all_labels), torch.cat(all_logits)\n",
    "\n",
    "# Compute ECE\n",
    "def compute_ece(probs, labels, n_bins=10):\n",
    "    probs = np.clip(probs, 1e-5, 1-1e-5)\n",
    "    confidences = np.max(probs, axis=1)\n",
    "    predictions = np.argmax(probs, axis=1)\n",
    "    accuracies = predictions == labels\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    ece = 0.0\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = (confidences >= bin_lower) & (confidences < bin_upper)\n",
    "        prop_in_bin = np.mean(in_bin)\n",
    "        if prop_in_bin > 0:\n",
    "            accuracy_in_bin = np.mean(accuracies[in_bin])\n",
    "            avg_confidence_in_bin = np.mean(confidences[in_bin])\n",
    "            ece += prop_in_bin * np.abs(avg_confidence_in_bin - accuracy_in_bin)\n",
    "    return ece\n",
    "\n",
    "# CutMix function\n",
    "def cutmix(images, labels, alpha=1.0):\n",
    "    batch_size = images.size(0)\n",
    "    indices = torch.randperm(batch_size)\n",
    "    shuffled_images = images[indices]\n",
    "    shuffled_labels = labels[indices]\n",
    "    \n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(images.size(), lam)\n",
    "    images[:, :, bby1:bby2, bbx1:bbx2] = shuffled_images[:, :, bby1:bby2, bbx1:bbx2]\n",
    "    \n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (images.size(-1) * images.size(-2)))\n",
    "    return images, labels, shuffled_labels, lam\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[3]\n",
    "    H = size[2]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "    \n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "    \n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    \n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "# Setup training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-5)\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "best_val_accuracy = 0.0\n",
    "best_epoch = 1\n",
    "best_model_path = \"deit_cifar100_full_finetune_cutmix_best_seed78_ep30_slow_LRpt\"\n",
    "\n",
    "model.train()\n",
    "for epoch in range(30):\n",
    "    start_time = time.time()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    if epoch < 5:\n",
    "        lr = 1e-4 * (epoch + 1) / 5\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    \n",
    "    # Add tqdm progress bar for training loop\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/30\", leave=True)\n",
    "    for images, labels in progress_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        if np.random.rand() < 0.5:\n",
    "            images, labels_a, labels_b, lam = cutmix(images, labels, alpha=1.0)\n",
    "            outputs = model(images).logits\n",
    "            loss = lam * criterion(outputs, labels_a) + (1 - lam) * criterion(outputs, labels_b)\n",
    "        else:\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Update progress bar with current loss\n",
    "        progress_bar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    progress_bar.close()\n",
    "    scheduler.step()\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    \n",
    "    val_loss, val_accuracy, val_probs, val_labels, val_logits = validate(model, val_loader, criterion, device)\n",
    "    epoch_time = time.time() - start_time\n",
    "    \n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        test_loss, test_accuracy, test_probs, test_labels, test_logits = validate(model, test_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1} - Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    if epoch > 4:\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"New best model saved at epoch {best_epoch} with Val Accuracy: {best_val_accuracy:.2f}%\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Val Accuracy: {val_accuracy:.2f}%, Time: {epoch_time:.2f}s, LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "# Plot metrics\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('full_finetune_cutmix_metrics_seed78_ep_30_slow_LR.png')\n",
    "plt.close()\n",
    "\n",
    "# Load best model for final evaluation\n",
    "model = DeiTForImageClassification.from_pretrained('facebook/deit-base-distilled-patch16-224')\n",
    "model.classifier = torch.nn.Linear(model.classifier.in_features, 100)\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "\n",
    "# Evaluate test set with calibration\n",
    "test_loss, test_accuracy, test_probs, test_labels, test_logits = validate(model, test_loader, criterion, device)\n",
    "ece = compute_ece(test_probs, test_labels)\n",
    "\n",
    "# Temperature scaling\n",
    "def find_optimal_temperature(val_logits, val_labels):\n",
    "    def ece_with_temp(temp):\n",
    "        scaled_probs = F.softmax(val_logits / temp, dim=1).numpy()\n",
    "        scaled_probs = np.clip(scaled_probs, 1e-5, 1-1e-5)\n",
    "        return compute_ece(scaled_probs, val_labels)\n",
    "    \n",
    "    temps = np.linspace(0.1, 5.0, 20)\n",
    "    eces = [ece_with_temp(t) for t in temps]\n",
    "    return temps[np.argmin(eces)]\n",
    "\n",
    "_, _, val_probs, val_labels, val_logits = validate(model, val_loader, criterion, device)\n",
    "optimal_temp = find_optimal_temperature(val_logits, val_labels)\n",
    "scaled_test_probs = F.softmax(test_logits / optimal_temp, dim=1).numpy()\n",
    "scaled_test_accuracy = accuracy_score(test_labels, np.argmax(scaled_test_probs, axis=1)) * 100\n",
    "scaled_ece = compute_ece(scaled_test_probs, test_labels)\n",
    "\n",
    "class_accuracies = []\n",
    "for i in range(100):\n",
    "    class_mask = test_labels == i\n",
    "    if class_mask.sum() > 0:\n",
    "        class_acc = accuracy_score(test_labels[class_mask], np.argmax(test_probs[class_mask], axis=1))\n",
    "        class_accuracies.append(class_acc)\n",
    "class_acc_mean = np.mean(class_accuracies)\n",
    "class_acc_std = np.std(class_accuracies)\n",
    "\n",
    "print(f\"Best Model (Epoch {best_epoch}) - Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"ECE: {ece:.4f}, Scaled ECE: {scaled_ece:.4f}, Scaled Test Accuracy: {scaled_test_accuracy:.2f}%\")\n",
    "print(f\"Class-wise Accuracy: Mean {class_acc_mean:.2f}, Std {class_acc_std:.2f}\")\n",
    "print(f\"Total training time: {(time.time() - start):.2f} seconds\")\n",
    "\n",
    "# Save final model\n",
    "torch.save(model.state_dict(), \"deit_cifar100_full_finetune_cutmix_final_seed78_ep30_slow_lr.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba08b6-4265-49f1-a99d-3f3917914a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e171b-0905-4d7c-989e-bd1904431a92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
